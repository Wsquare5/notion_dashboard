#!/usr/bin/env python3
"""
Aggregate spot (USDT) and USDT-M perpetual data by base asset.

Reads `data/sample.json` (generated by fetch script) and writes:
 - data/aggregated_usdt.json
 - data/aggregated_usdt.csv

Each row contains: base, spot_price (USD or None), perp_price (USD or None), openInterest, market_cap, fdv, coingecko_id
"""
from __future__ import annotations

import json
import csv
import os
from typing import Dict, Optional


def load_sample(path: str = "data/sample.json") -> Dict:
    with open(path, "r") as f:
        return json.load(f)


def is_usdt_pair(symbol: str) -> bool:
    return symbol.endswith("USDT")


def aggregate(sample: Dict) -> Dict[str, Dict]:
    out: Dict[str, Dict] = {}
    spot = sample.get("spot", [])
    perp = sample.get("perp", [])

    # process spot (only USDT quote)
    for s in spot:
        sym = s.get("symbol")
        if not sym or not is_usdt_pair(sym):
            continue
        base = s.get("base")
        # normalize base if symbol like BTCUSDT -> base BTC
        if sym.endswith("USDT"):
            base = sym[:-4]
        r = out.setdefault(base, {"base": base, "spot_price": None, "perp_price": None, "openInterest": None, "market_cap": None, "fdv": None, "coingecko_id": None})
        r["spot_price"] = s.get("price")
        # prefer coingecko id from spot if available
        if s.get("coingecko_id"):
            r["coingecko_id"] = s.get("coingecko_id")

    # process perp
    for p in perp:
        sym = p.get("symbol")
        if not sym or not is_usdt_pair(sym):
            continue
        base = p.get("base")
        if sym.endswith("USDT"):
            base = sym[:-4]
        r = out.setdefault(base, {"base": base, "spot_price": None, "perp_price": None, "openInterest": None, "market_cap": None, "fdv": None, "coingecko_id": None})
        r["perp_price"] = p.get("price")
        r["openInterest"] = p.get("openInterest")
        # market cap and fdv from coingecko
        if p.get("market_cap") is not None:
            r["market_cap"] = p.get("market_cap")
        if p.get("fdv") is not None:
            r["fdv"] = p.get("fdv")
        if p.get("coingecko_id") and not r.get("coingecko_id"):
            r["coingecko_id"] = p.get("coingecko_id")

    return out


def write_outputs(agg: Dict[str, Dict], json_path: str = "data/aggregated_usdt.json", csv_path: str = "data/aggregated_usdt.csv") -> None:
    os.makedirs(os.path.dirname(json_path) or ".", exist_ok=True)
    with open(json_path, "w") as f:
        json.dump(list(agg.values()), f, indent=2, ensure_ascii=False)

    # write CSV
    with open(csv_path, "w", newline='') as csvfile:
        writer = csv.writer(csvfile)
        header = ["base", "spot_price", "perp_price", "openInterest", "market_cap", "fdv", "coingecko_id"]
        writer.writerow(header)
        for row in agg.values():
            writer.writerow([row.get(h) for h in header])


def main():
    sample = load_sample()
    agg = aggregate(sample)
    write_outputs(agg)
    print(f"Wrote aggregated {len(agg)} bases to data/aggregated_usdt.json and data/aggregated_usdt.csv")


if __name__ == "__main__":
    main()
#!/usr/bin/env python3
"""
Aggregate spot (USDT) and USDT-M perpetual data by base asset.

Reads `data/sample.json` produced by `fetch_binance_markets.py` and writes
`data/aggregated_usdt.json` and `data/aggregated_usdt.csv`.
"""
import json
import csv
import os
from typing import Dict, Any


IN_PATH = os.path.join(os.path.dirname(__file__), "..", "data", "sample.json")
OUT_JSON = os.path.join(os.path.dirname(__file__), "..", "data", "aggregated_usdt.json")
OUT_CSV = os.path.join(os.path.dirname(__file__), "..", "data", "aggregated_usdt.csv")


def load_sample(path: str) -> Dict[str, Any]:
    with open(path, "r") as f:
        return json.load(f)


def is_usdt_pair(symbol: str) -> bool:
    return symbol.endswith("USDT")


def base_from_symbol(symbol: str) -> str:
    if is_usdt_pair(symbol):
        return symbol[:-4]
    return symbol


def aggregate(data: Dict[str, Any]) -> Dict[str, Dict[str, Any]]:
    out: Dict[str, Dict[str, Any]] = {}

    # process spot: consider only USDT-quoted spot pairs
    for s in data.get("spot", []):
        sym = s.get("symbol")
        if not is_usdt_pair(sym):
            continue
        base = base_from_symbol(sym)
        rec = out.setdefault(base, {"base": base, "spot_price": None, "perp_price": None, "openInterest": None, "market_cap": None, "fdv": None})
        rec["spot_price"] = s.get("price")
        # prefer market cap from spot if exists
        if s.get("market_cap"):
            rec["market_cap"] = s.get("market_cap")
        if s.get("fdv"):
            rec["fdv"] = s.get("fdv")

    # process perp
    for p in data.get("perp", []):
        sym = p.get("symbol")
        # perp list should be USDT quotes already
        if not is_usdt_pair(sym):
            continue
        base = base_from_symbol(sym)
        rec = out.setdefault(base, {"base": base, "spot_price": None, "perp_price": None, "openInterest": None, "market_cap": None, "fdv": None})
        rec["perp_price"] = p.get("price")
        rec["openInterest"] = p.get("openInterest")
        # take market cap/fdv from perp if spot didn't have
        if p.get("market_cap") and not rec.get("market_cap"):
            rec["market_cap"] = p.get("market_cap")
        if p.get("fdv") and not rec.get("fdv"):
            rec["fdv"] = p.get("fdv")

    return out


def write_outputs(agg: Dict[str, Dict[str, Any]]):
    os.makedirs(os.path.dirname(OUT_JSON), exist_ok=True)
    with open(OUT_JSON, "w") as f:
        json.dump(list(agg.values()), f, indent=2, ensure_ascii=False)
    with open(OUT_CSV, "w", newline="") as f:
        writer = csv.writer(f)
        writer.writerow(["base", "spot_price", "perp_price", "openInterest", "market_cap", "fdv"])
        for r in agg.values():
            writer.writerow([r.get("base"), r.get("spot_price"), r.get("perp_price"), r.get("openInterest"), r.get("market_cap"), r.get("fdv")])


def main():
    data = load_sample(IN_PATH)
    agg = aggregate(data)
    write_outputs(agg)
    print(f"Wrote aggregated {len(agg)} rows to {OUT_JSON} and {OUT_CSV}")


if __name__ == "__main__":
    main()
